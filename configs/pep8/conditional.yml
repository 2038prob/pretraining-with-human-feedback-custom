dataset:
  is_split_by_sentences: true
  datasets:
    - "kejian/codeparrot-train-more-filter-3.3b-cleaned"

  conditional_training_config:
    threshold: 0
    aligned_prefix: "<|aligned|>"
    misaligned_prefix: "<|misaligned|>"
    drop_token_fraction: 0.1

tokenizer:
  path_or_name: codeparrot/codeparrot-small
  special_tokens:
    - "<|aligned|>"
    - "<|misaligned|>"

model:
  path_or_name: codeparrot/codeparrot-small
  from_scratch: true
  num_additional_tokens: 2
  gpt2_config_kwargs:
      reorder_and_upcast_attn: true
      scale_attn_by: true

objective:
  name: MLE

training:
  output_dir: training_output
  effective_batch_size: 64
  num_tokens: 3.3E+9
  learning_rate: 0.0008
  per_device_train_batch_size: 16
  fp16: true
  weight_decay: 0.1
  evaluation_strategy: 'no'
  logging_steps: 1
  warmup_ratio: 0.01
  logging_first_step: true
  seed: 42
  remove_unused_columns: false
  dataloader_num_workers: 0
  save_strategy: steps
  save_steps: 25177
  hub_strategy: all_checkpoints
  push_to_hub: true
  hub_model_id: kejian/test-condpep8

generation:
  scorer_config:
    class_name: PEP8Scorer
  metrics_configs:
    - class_name: Length
    - class_name: NGramStats
      n: 1
    - class_name: Compilability

  batch_size: 128
  scenario_configs:
    - name: unconditional
      display_as_html: true
      num_samples: 4096
      num_hits_threshold: 0
      prefix: "<|aligned|>"
      use_prompt_for_scoring: false
      generate_kwargs:
        do_sample: true
        max_length: 640
        min_length: 10
        temperature: 0.7
        top_p: 0.9
        top_k: 0
        eos_token_id: 0
        bad_words_ids: [[32769]]
      
    - name: functions
      prompts_path: resources/functions_csnet.jsonl
      display_as_html: true
      num_samples: 4096
      num_hits_threshold: 0
      prefix: "<|aligned|>"
      prompt_before_control: true
      use_prompt_for_scoring: true
      generate_kwargs:
        do_sample: true
        max_length: 272
        min_length: 10
        temperature: 0.7
        top_p: 0.9
        top_k: 0
        eos_token_id: 0
        bad_words_ids: [[32769]]

kl_gpt3_callback:
  num_samples: 4096
  max_tokens: 64
  prefix: "<|aligned|>"
  should_insert_prefix: true
  gpt3_kwargs:
    model_name: code-cushman-001
